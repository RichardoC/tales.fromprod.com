<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://tales.fromprod.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tales.fromprod.com/" rel="alternate" type="text/html" /><updated>2024-03-31T00:07:44+00:00</updated><id>https://tales.fromprod.com/feed.xml</id><title type="html">Tales from Prod</title><subtitle>Welcome to Richard Finlay Tweed&apos;s thoughts on Cloud Native Software, Kubernetes, Production and whatever else he&apos;s been tinkering with.</subtitle><entry><title type="html">Using a video as a Google Meet background</title><link href="https://tales.fromprod.com/2024/082/google-meet-background-videos.html" rel="alternate" type="text/html" title="Using a video as a Google Meet background" /><published>2024-03-22T20:00:00+00:00</published><updated>2024-03-22T20:00:00+00:00</updated><id>https://tales.fromprod.com/2024/082/google-meet-background-videos</id><content type="html" xml:base="https://tales.fromprod.com/2024/082/google-meet-background-videos.html"><![CDATA[<h1 id="using-a-video-as-a-google-meet-background">Using a video as a Google Meet background</h1>

<p><strong>Warning</strong>
This is not officially supported by Google, and could be considered against their <a href="https://support.google.com/meet/answer/9847091">terms of service (specifically “System interference”)</a> so follow this guide at your own risk.</p>

<p><strong>I accept no responsibility for how anyone chooses to use this. As always - Don’t be a pain</strong></p>

<p>Don’t worry, at this time (2024-03-22) it only uses the video, not the audio channel.</p>

<h2 id="requirements">Requirements</h2>

<ul>
  <li>An mp4 video which you have the rights to use</li>
  <li>A browser where you can edit a page’s HTML</li>
  <li>Some patience</li>
</ul>

<h2 id="guide">Guide</h2>

<ul>
  <li>Join a Google Meet call</li>
  <li>click the menu (three vertical dots)</li>
  <li>select Apply visual effects</li>
  <li>Use inspector on the <code class="language-plaintext highlighter-rouge">Add your own personal background</code> button</li>
  <li>You should then see something like <code class="language-plaintext highlighter-rouge">&lt;input type="file" jsname="tif8Pe" jsaction="change:E7zRc" accept="image/jpeg, image/png, image/webp" style="display: none;"&gt;</code> in the HTML
    <ul>
      <li>edit this to include <code class="language-plaintext highlighter-rouge">video/mp4</code></li>
    </ul>
  </li>
  <li>Click the <code class="language-plaintext highlighter-rouge">Add your own personal background</code> button</li>
  <li>Select your mp4 video</li>
</ul>

<p>Congratulations, you’ve now set a video as your background.
The video audio is <em>not</em> sent</p>

<h2 id="dirty-javascript-hacks-to-do-this">Dirty javascript hacks to do this</h2>

<p>** Warning ** This is GPT generated, run at your own risk</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Find the first &lt;input&gt; element with the specific attributes</span>
<span class="kd">const</span> <span class="nx">inputFile</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">querySelector</span><span class="p">(</span><span class="dl">'</span><span class="s1">input[type="file"][accept*="image/jpeg"], input[type="file"][accept*="image/png"], input[type="file"][accept*="image/webp"]</span><span class="dl">'</span><span class="p">);</span>

<span class="k">if</span> <span class="p">(</span><span class="nx">inputFile</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Get the current accept attribute value</span>
    <span class="kd">const</span> <span class="nx">currentAcceptValue</span> <span class="o">=</span> <span class="nx">inputFile</span><span class="p">.</span><span class="nx">getAttribute</span><span class="p">(</span><span class="dl">'</span><span class="s1">accept</span><span class="dl">'</span><span class="p">);</span>
    <span class="c1">// Check if "video/mp4" is already included, if not, add it</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">currentAcceptValue</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="dl">'</span><span class="s1">video/mp4</span><span class="dl">'</span><span class="p">))</span> <span class="p">{</span>
        <span class="nx">inputFile</span><span class="p">.</span><span class="nx">setAttribute</span><span class="p">(</span><span class="dl">'</span><span class="s1">accept</span><span class="dl">'</span><span class="p">,</span> <span class="s2">`</span><span class="p">${</span><span class="nx">currentAcceptValue</span><span class="p">}</span><span class="s2">, video/mp4`</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="steps-to-using-this-javascript">Steps to using this javascript</h2>

<ul>
  <li>Join a Google Meet call</li>
  <li>Open the developer console</li>
  <li>paste in that javascript and run it</li>
  <li>Click the <code class="language-plaintext highlighter-rouge">Add your own personal background</code> button</li>
  <li>Select your mp4 video</li>
</ul>

<p>Congratulations, you’ve now set a video as your background
The video audio is <em>not</em> sent</p>]]></content><author><name></name></author><category term="Google" /><category term="Nonsense" /><summary type="html"><![CDATA[Using a video as a Google Meet background]]></summary></entry><entry><title type="html">Making a custom GPT with chatgpt for cloudquery data</title><link href="https://tales.fromprod.com/2024/067/custom-chatgpt-cloudquery.html" rel="alternate" type="text/html" title="Making a custom GPT with chatgpt for cloudquery data" /><published>2024-03-07T20:00:00+00:00</published><updated>2024-03-07T20:00:00+00:00</updated><id>https://tales.fromprod.com/2024/067/custom-chatgpt-cloudquery</id><content type="html" xml:base="https://tales.fromprod.com/2024/067/custom-chatgpt-cloudquery.html"><![CDATA[<h1 id="making-a-custom-gpt-with-chatgpt-for-cloudquery-data">Making a custom GPT with chatgpt for cloudquery data</h1>

<p>This assumes you followed <a href="https://help.openai.com/en/articles/8554397-creating-a-gpt">https://help.openai.com/en/articles/8554397-creating-a-gpt</a> and have already generated “instructions” for the GPT.</p>

<p>First get the cloudquery docs
<code class="language-plaintext highlighter-rouge">git clone git@github.com:cloudquery/cloudquery.git</code></p>

<p>Get the cloudquery tables files as these have the relevant schemas and put them in a temporary directory for upload</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> /tmp/docs
find <span class="nb">.</span> <span class="nt">-type</span> d <span class="nt">-name</span> <span class="s2">"tables"</span> | xargs <span class="nt">-I</span><span class="o">{}</span> <span class="nb">cp</span> <span class="nt">-r</span> <span class="o">{}</span>/ /tmp/docs/
</code></pre></div></div>
<p>We now have the markdown we want in /tmp/docs/tables</p>

<p>Unfortunately you can only upload 20 files, so we need to cat all these together</p>

<p><code class="language-plaintext highlighter-rouge">cat * &gt; ../schemas.md</code></p>

<p>After that, we need to teach the bot about GoogleSQL as it doesn’t understand it, so copy all the docs from <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax">https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax</a> and put those into another file called <code class="language-plaintext highlighter-rouge">googlesql.txt</code>.</p>

<p>Now upload these two files (schema.md and googlesql.txt) as “knowledge”</p>

<p>Update your prompt to tell your bot to only use the schema and SQL details that are in its knowledge.</p>

<p>Below is an example of what I used</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
CloudQuery Crafter is designed to handle requests for creating SQL queries based on specific data needs, such as finding all EC2 instances with a public IP. It will access and interpret relevant table schemas from it's knowledge to ensure accurate query generation. For each request, CloudQuery Crafter will provide detailed explanations and the complete SQL query, focusing on clarity and efficiency. It's tailored for users ranging from beginners to experts in SQL, aiming to facilitate their database querying process. CloudQuery Crafter prioritizes providing optimized, ready-to-use queries, including all necessary details such as 'SELECT' fields and 'WHERE' conditions to meet the user's specific request. CloudQuery Crafter should ensure they are providing the correct SQL for the database in use, for example postgres or Bigquery. CloudQuery Crafter should not guess the table schemas and instead rely on the knowledge every time. CloudQuery Crafter can also use queries on https://kmcquade.com/cloudquery/#ec2-instances-with-public-ips to guide it.
Do not invent any tables. If they are not mentioned in CloudQuery Crafter's knowledge they do not exist.
Unless told otherwise, use GoogleSQL SQL dialect which is documented in CloudQuery Crafter's knowledge.
</code></pre></div></div>

<p>This GPT can be used at <a href="https://chat.openai.com/g/g-2guyuhcpP-cloudquery-crafter">https://chat.openai.com/g/g-2guyuhcpP-cloudquery-crafter</a></p>

<p>If you’ve any issues or ideas for improvements, please let me know.</p>]]></content><author><name></name></author><category term="ChatGPT" /><category term="cloudquery" /><summary type="html"><![CDATA[Making a custom GPT with chatgpt for cloudquery data]]></summary></entry><entry><title type="html">Finding secrets on GitLab</title><link href="https://tales.fromprod.com/2024/056/gitlab-secrets.html" rel="alternate" type="text/html" title="Finding secrets on GitLab" /><published>2024-02-25T11:00:00+00:00</published><updated>2024-02-25T11:00:00+00:00</updated><id>https://tales.fromprod.com/2024/056/gitlab-secrets</id><content type="html" xml:base="https://tales.fromprod.com/2024/056/gitlab-secrets.html"><![CDATA[<h1 id="finding-secrets-on-gitlab">Finding secrets on GitLab</h1>

<p>Everyone’s been there before, you included something you shouldn’t have in a commit so you undo the commit and force push.</p>

<p>This data’s gone, right?(!)</p>

<p>This blog post is about finding those mistakenly published commits, and to serve as a reminder that you should always rotate potentially exposed credentials even if you think you’ve deleted them.</p>

<h2 id="how-can-these-missing-commits-still-exist">How can these “missing commits” still exist?</h2>

<p>When you force pushed your branch you rewrote the branch history to no longer reference those commits. This doesn’t remove those commits though, it just detached them from the chain of commits that represents the branch.  commits still exist on the GitLab server despite being inaccessible via the branches.</p>

<p>Here’s a writeup of how this works <a href="https://git-scm.com/book/en/v2/Git-Internals-Maintenance-and-Data-Recovery">locally</a></p>

<h2 id="how-do-we-find-these-missing-commits">How do we find these missing commits</h2>

<p>In theory GitLab have an API for getting commits from a repository, and there’s a parameter for getting <code class="language-plaintext highlighter-rouge">all</code> commits.</p>

<p>As of the time of writing, this API fails to return these dangling commits <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/443263">https://gitlab.com/gitlab-org/gitlab/-/issues/443263</a> which I consider a bug.</p>

<p>However, every time a commit is pushed a <code class="language-plaintext highlighter-rouge">pushed to</code> <a href="https://docs.gitlab.com/ee/api/events.html">event</a> is generated by GitLab. An example of this is below.</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">3182909502</span><span class="p">,</span><span class="w">
    </span><span class="nl">"project_id"</span><span class="p">:</span><span class="w"> </span><span class="mi">55263882</span><span class="p">,</span><span class="w">
    </span><span class="nl">"action_name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"pushed to"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"target_id"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
    </span><span class="nl">"target_iid"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
    </span><span class="nl">"target_type"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
    </span><span class="nl">"author_id"</span><span class="p">:</span><span class="w"> </span><span class="mi">20255114</span><span class="p">,</span><span class="w">
    </span><span class="nl">"target_title"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span><span class="w">
    </span><span class="nl">"created_at"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2024-02-24T21:29:08.711Z"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"author"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"id"</span><span class="p">:</span><span class="w"> </span><span class="mi">20255114</span><span class="p">,</span><span class="w">
      </span><span class="nl">"username"</span><span class="p">:</span><span class="w"> </span><span class="s2">"RichardoC"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Richard Tweed"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"state"</span><span class="p">:</span><span class="w"> </span><span class="s2">"active"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"locked"</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w">
      </span><span class="nl">"avatar_url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://secure.gravatar.com/avatar/3af3c4bc67b146186dbd2ef852f8faa16c91d9268e81b7b292168e7dc1fdc7b6?s=80&amp;d=identicon"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"web_url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://gitlab.com/RichardoC"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"push_data"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"commit_count"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
      </span><span class="nl">"action"</span><span class="p">:</span><span class="w"> </span><span class="s2">"pushed"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ref_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"branch"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"commit_from"</span><span class="p">:</span><span class="w"> </span><span class="s2">"31ed8bb6dd627bd38fba1aa350a15136c636c932"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"commit_to"</span><span class="p">:</span><span class="w"> </span><span class="s2">"7faedfa06dd7dda69ca94169c9ec01aa605da08b"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ref"</span><span class="p">:</span><span class="w"> </span><span class="s2">"main"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"commit_title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Tidy readme"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"ref_count"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"author_username"</span><span class="p">:</span><span class="w"> </span><span class="s2">"RichardoC"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>These events reference the <code class="language-plaintext highlighter-rouge">commit_from</code> and <code class="language-plaintext highlighter-rouge">commit_to</code> commits. These can be used to generate a set of all commits that actually happened over the last 3 years (they’re only retained for 3 years)</p>

<p>By comparing that set with the official history (the all commits API above) we can find dangling commits, and generate the URL where they can be seen.</p>

<h2 id="very-cool-wheres-the-code">Very cool, where’s the code?</h2>

<p><a href="https://github.com/RichardoC/gitlab-secrets">https://github.com/RichardoC/gitlab-secrets</a></p>

<p>An example Gitlab repo with dangling commits can be found at <a href="https://gitlab.com/gitlab-secrets/gitlab-secrets">https://gitlab.com/gitlab-secrets/gitlab-secrets</a> for you to test this out with</p>

<h2 id="original-idea">Original idea</h2>

<p>This was based on the work by Neodyme where they used this technique to find secrets on <a href="https://neodyme.io/en/blog/github_secrets/">GitHub</a></p>]]></content><author><name></name></author><category term="APIs" /><category term="git" /><summary type="html"><![CDATA[Finding secrets on GitLab]]></summary></entry><entry><title type="html">Pass through JSON logs with vector or filebeat</title><link href="https://tales.fromprod.com/2023/305/pass-through-json-logs.html" rel="alternate" type="text/html" title="Pass through JSON logs with vector or filebeat" /><published>2023-11-01T11:00:00+00:00</published><updated>2023-11-01T11:00:00+00:00</updated><id>https://tales.fromprod.com/2023/305/pass-through-json-logs</id><content type="html" xml:base="https://tales.fromprod.com/2023/305/pass-through-json-logs.html"><![CDATA[<h1 id="pass-through-json-logs-with-vector-or-filebeat">Pass through JSON logs with vector or filebeat</h1>

<p>Say you are using an application that emits JSON formatted logs, with one log per line in the log file, and you want to store these in ElasticSearch and view them natively in kibana - how would you manage this?</p>

<p>Both Vector and filebeat have quirks, so I’ve written this guide on how I got these log processors to perform as I wanted - just passing through the original json object so elastic search can parse it as expected</p>

<h2 id="vector">Vector</h2>

<p><a href="https://vector.dev/docs/">Vector</a> is a log processor written in Rust supported by Datadog.</p>

<p>One of the main quirks is that it automatically puts you message in <code class="language-plaintext highlighter-rouge">.message</code> in the data model, with some other metadata that isn’t documented in any single place</p>

<p>Using the snippet below, the logs are read from a series of files in <code class="language-plaintext highlighter-rouge">tmp</code> that have a json object on each line, and are named “my_log” with a suffix</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># vector.yaml</span>

<span class="nn">---</span>
<span class="na">healthchecks</span><span class="pi">:</span>
  <span class="na">enabled</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">require_healthy</span><span class="pi">:</span> <span class="no">true</span>
<span class="na">sources</span><span class="pi">:</span>
  <span class="na">my_application_log_file</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">file</span>
    <span class="na">include</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">/tmp/my-log*</span>
<span class="na">transforms</span><span class="pi">:</span>
  <span class="na">audit_files_json_parser</span><span class="pi">:</span>
    <span class="na">inputs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">my_application_log_file</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">remap</span>
    <span class="na">source</span><span class="pi">:</span> <span class="pi">|-</span>
      <span class="s">. = parse_json!(.message)</span>
<span class="na">sinks</span><span class="pi">:</span>
  <span class="na">elasticsearch</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">elasticsearch</span>
    <span class="na">inputs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">audit_files_json_parser</span>
    <span class="na">auth</span><span class="pi">:</span>
      <span class="na">strategy</span><span class="pi">:</span> <span class="s">basic</span>
      <span class="na">user</span><span class="pi">:</span> <span class="s2">"</span><span class="s">${ELASTICSEARCH_USER}"</span>
      <span class="na">password</span><span class="pi">:</span> <span class="s2">"</span><span class="s">${ELASTICSEARCH_PASSWORD}"</span>
    <span class="na">endpoints</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">${ELASTICSEARCH_URL}"</span><span class="pi">]</span>
    <span class="na">bulk</span><span class="pi">:</span>
      <span class="na">index</span><span class="pi">:</span> <span class="s2">"</span><span class="s">my_application"</span>
      <span class="na">action</span><span class="pi">:</span> <span class="s">create</span>
    <span class="na">mode</span><span class="pi">:</span> <span class="s">bulk</span>
</code></pre></div></div>

<h2 id="filebeat">Filebeat</h2>

<p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/index.html">Filebeat</a> is a log processor maintained by Elastic</p>

<p>The equivalent configuration for filebeat is</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">filebeat.inputs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">type</span><span class="pi">:</span> <span class="s">filestream</span>
    <span class="na">id</span><span class="pi">:</span> <span class="s">my_application_log_file</span>
    <span class="na">paths</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">/tmp/my-log*</span>

<span class="na">processors</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">decode_json_fields</span><span class="pi">:</span>
      <span class="na">fields</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">message</span><span class="pi">]</span>
      <span class="na">process_array</span><span class="pi">:</span> <span class="no">false</span>
      <span class="na">max_depth</span><span class="pi">:</span> <span class="m">2</span>
      <span class="na">overwrite_keys</span><span class="pi">:</span> <span class="no">true</span>
      <span class="na">add_error_key</span><span class="pi">:</span> <span class="no">true</span>
  <span class="pi">-</span> <span class="na">move_fields</span><span class="pi">:</span>
      <span class="na">from</span><span class="pi">:</span> <span class="s2">"</span><span class="s">message"</span>
      <span class="na">fields</span><span class="pi">:</span> <span class="pi">[]</span>
      <span class="na">to</span><span class="pi">:</span> <span class="s2">"</span><span class="s">"</span> <span class="c1"># move message fields up to root</span>

<span class="na">output.elasticsearch</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">${ELASTICSEARCH_URL}'</span><span class="pi">]</span>
  <span class="na">username</span><span class="pi">:</span> <span class="s">${ELASTICSEARCH_USER}</span>
  <span class="na">password</span><span class="pi">:</span> <span class="s">${ELASTICSEARCH_PASSWORD}</span>
  <span class="na">index</span><span class="pi">:</span> <span class="s">my_application</span>
  <span class="na">bulk_max_size</span><span class="pi">:</span> <span class="m">50</span>
  <span class="na">compression_level</span><span class="pi">:</span> <span class="m">3</span>

<span class="na">logging.to_stderr</span><span class="pi">:</span> <span class="no">true</span>


</code></pre></div></div>

<h3 id="gotchas">Gotchas</h3>

<p>Despite the docs claiming that the following works, it won’t with a particularly unhelpful error message <code class="language-plaintext highlighter-rouge">{\"type\":\"document_parsing_exception\",\"reason\":\"[1:1537] object mapping for [message] tried to parse field [message] as object, but found a concrete value\"}, dropping event!","service.name":"filebeat","ecs.version":"1.6.0"}</code></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="pi">-</span> <span class="na">decode_json_fields</span><span class="pi">:</span>
      <span class="na">fields</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">message</span><span class="pi">]</span>
      <span class="na">process_array</span><span class="pi">:</span> <span class="no">false</span>
      <span class="na">max_depth</span><span class="pi">:</span> <span class="m">2</span>
      <span class="na">overwrite_keys</span><span class="pi">:</span> <span class="no">true</span>
      <span class="na">add_error_key</span><span class="pi">:</span> <span class="no">true</span>
      <span class="na">target</span><span class="pi">:</span> <span class="s2">"</span><span class="s">"</span> <span class="c1"># will place the json in the root object</span>
</code></pre></div></div>

<p>My best guess is that it needs to do this in two operations rather than one, hence the snippet above.</p>]]></content><author><name></name></author><category term="JSON" /><category term="logging" /><category term="ElasticSearch" /><summary type="html"><![CDATA[Pass through JSON logs with vector or filebeat]]></summary></entry><entry><title type="html">Bulk deleting tickets in Jira</title><link href="https://tales.fromprod.com/2023/177/bulk-deleting-in-jira.html" rel="alternate" type="text/html" title="Bulk deleting tickets in Jira" /><published>2023-06-26T21:00:00+01:00</published><updated>2023-06-26T21:00:00+01:00</updated><id>https://tales.fromprod.com/2023/177/bulk-deleting-in-jira</id><content type="html" xml:base="https://tales.fromprod.com/2023/177/bulk-deleting-in-jira.html"><![CDATA[<h1 id="bulk-deleting-tickets-in-jira">Bulk deleting tickets in Jira</h1>
<p>For the sake of argument, say your automation developers have a test project for testing their tooling which automatically raises a jira ticket when it finds something a human needs to deal with. This is fantastic, until a few months later when the tooling changes, and the 10,000s of old tickets are no longer “correct” in the test project.</p>

<p>So, you want to clean up the old tickets, so only the new “valid” tickets exist in this test project.</p>

<h2 id="approach-1---use-the-bulk-edit-functionality">Approach 1 - use the bulk edit functionality</h2>

<p>Jira has a <a href="https://confluence.atlassian.com/jirasoftwareserver/editing-multiple-issues-at-the-same-time-939938937.html">bulk edit functionality</a>, that can be used for deleting issues. Unfortunately it only allows 1,000 issues at a time but surely running that 10 ish times is fine… right?</p>

<h3 id="problem">Problem</h3>

<p>It takes 12 minutes to delete the 1,000 issues. Sitting here for multiple hours triggering bulk delete through the UI isn’t how you want to spend you day.</p>

<h2 id="approach-2---use-the-apis">Approach 2 - use the APIs</h2>

<p>Atlassian have many APIs for Jira, and <a href="https://developer.atlassian.com/cloud/jira/platform/rest/v3/api-group-issues/#api-rest-api-3-issue-issueidorkey-delete">reasonable docs</a> for them as well!</p>

<h3 id="the-good">The good</h3>

<ul>
  <li>Jira has APIs</li>
</ul>

<h3 id="the-bad">The bad</h3>

<ul>
  <li>Jira doesn’t have a <a href="https://community.developer.atlassian.com/t/jira-rest-api-endpoint-for-bulk-delete-issues/55806">bulk delete API</a></li>
  <li>Jira won’t necessarily give you all matching issues from an issue search API call, depending on how much data is in each issue</li>
</ul>

<h3 id="the-how">The how</h3>

<p>Assuming the following</p>
<ul>
  <li>Your atlassian cloud instance URL is <a href="https://example.atlassian.net">https://example.atlassian.net</a></li>
  <li>You’re using bash on a *nix</li>
  <li>You have issued a JIRA API token from <a href="https://id.atlassian.com/manage-profile/security">https://id.atlassian.com/manage-profile/security</a> and exported it as JIRA_API_TOKEN in your shell</li>
  <li>You’ve exported your atlassian user email as JIRA_EMAIL</li>
  <li>You have a JQL query that matches the issues you want to delete, and ONLY the issues you want to delete and have exported it (URL encoded) as JIRA_JQL</li>
</ul>

<p>Example URL encoded JQL is <code class="language-plaintext highlighter-rouge">project%20%3D%20TOY%20AND%20issuetype%20%3D%20Vulnerability%20ORDER%20BY%20created%20DESC</code> which matches all vulnerability issues in a project called TOY</p>

<h3 id="final-script">Final script</h3>

<p>OBLIGATORY WARNING - this will delete all issues which match the JQL, and ALL subtasks use with caution!</p>

<p>This script will attempt to delete the issues, with 12 parallel threads. It has zero error handling or backoff so you are likely to get <code class="language-plaintext highlighter-rouge">429 - Too many requests</code> and should cancel the script and wait a few minutes before resuming.
During this time your user will be unable to use the Jira webapp as well, as it’s your user that gets rate limited, not the API token.</p>

<p>You may also have to rerun this script multiple times if you have more than ~ 10,000 issues, as this doesn’t follow any pagination.</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">curl --request GET \
</span><span class="gp">  --url "https://example.atlassian.net/rest/api/3/search?maxResults=20000&amp;fields=id&amp;jql=$</span>JIRA_JQL<span class="s2">"  </span><span class="se">\</span><span class="s2">
</span><span class="gp">  --user "$</span><span class="s2">JIRA_EMAIL:</span><span class="nv">$JIRA_API_TOKEN</span><span class="s2">"</span> <span class="se">\</span>
<span class="gp">  --header 'Accept: application/json' | jq -r '.issues[].id'  | xargs -P12 -I{} bash -c 'curl --request DELETE   --url 'https://example.atlassian.net/rest/api/3/issue/{}?deleteSubtasks=true'  --user "$</span>JIRA_EMAIL:<span class="nv">$JIRA_API_TOKEN</span><span class="s2">" &amp;&amp; echo "</span><span class="o">{}</span> completed<span class="s2">" || echo "</span><span class="o">{}</span> failed<span class="s2">"'
</span><span class="go">14054 completed
14050 completed
</span><span class="c">...
</span></code></pre></div></div>]]></content><author><name></name></author><category term="Jira" /><category term="APIs" /><category term="Atlassian" /><summary type="html"><![CDATA[Bulk deleting tickets in Jira For the sake of argument, say your automation developers have a test project for testing their tooling which automatically raises a jira ticket when it finds something a human needs to deal with. This is fantastic, until a few months later when the tooling changes, and the 10,000s of old tickets are no longer “correct” in the test project.]]></summary></entry><entry><title type="html">Getting started with LLMs locally</title><link href="https://tales.fromprod.com/2023/099/getting-started-with-llms-locally.html" rel="alternate" type="text/html" title="Getting started with LLMs locally" /><published>2023-04-09T20:00:00+01:00</published><updated>2023-04-09T20:00:00+01:00</updated><id>https://tales.fromprod.com/2023/099/getting-started-with-llms-locally</id><content type="html" xml:base="https://tales.fromprod.com/2023/099/getting-started-with-llms-locally.html"><![CDATA[<h1 id="getting-started-with-llms-locally">Getting started with LLMs locally</h1>

<p>So you’ve heard all the hype about Large Language Models (LLM) and want to run one yourself locally. This guide details how</p>

<h2 id="why-would-i-want-to-run-it-locally">Why would I want to run it locally?</h2>

<ul>
  <li>You want to peer behind the curtain of what’s actually happening</li>
  <li>You don’t want you prompts to be sent to a third party</li>
  <li>You want to test the LLM with sensitive intellectual property</li>
  <li>Why not?</li>
</ul>

<h2 id="prerequisites">Prerequisites</h2>

<ul>
  <li>Ubuntu (ish)</li>
  <li>Huge amounts of ram, or a huge <a href="https://help.ubuntu.com/community/SwapFaq">swapfile/swap</a> partition. 32GB+ is commonly required</li>
  <li>Python experience</li>
  <li>A fast internet connection</li>
  <li>50GB+ free storage space</li>
</ul>

<h2 id="getting-started-guide">Getting started guide</h2>

<p>Install <a href="https://docs.docker.com/engine/install/debian/">Docker</a></p>

<p>If you have an nvidia GPU configured with cuda you might be able to follow <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html</a> to use GPU acceleration.</p>

<p>Install git and git lfs and set it up.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt <span class="nb">install </span>git git-lfs
git lfs <span class="nb">install</span>
</code></pre></div></div>

<p>Download the docker image with all the tools you need, this is ~ 10GB</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull huggingface/transformers-all-latest-gpu
</code></pre></div></div>

<p>Discover the model you want to play with on Hugging Face such as <a href="https://huggingface.co/cerebras/Cerebras-GPT-2.7B">https://huggingface.co/cerebras/Cerebras-GPT-2.7B</a></p>

<p>You can download it by cloning the git repo (~11GB)</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://huggingface.co/cerebras/Cerebras-GPT-2.7B
</code></pre></div></div>

<p>Now to run the model</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-it</span> <span class="nt">--rm</span>  <span class="nt">-v</span> <span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span>:/model docker.io/huggingface/transformers-all-latest-gpu
<span class="c"># From now all commands are inside the container</span>
<span class="nb">cd</span> /model
<span class="c"># start a python interpreter to use</span>
python3
<span class="c"># from now all commands are inside the python interpreter</span>
</code></pre></div></div>

<h3 id="actually-playing-with-the-model">Actually playing with the model</h3>

<p>Now for the Python, in the REPL terminal.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This stage will take a while as it loads the model into ram, and may lead to it getting OOMK
</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"./Cerebras-GPT-2.7B"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"./Cerebras-GPT-2.7B"</span><span class="p">)</span>

<span class="c1"># convenience function to wrap the steps from prompt to reponse
</span><span class="k">def</span> <span class="nf">model_on_prompt</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                        <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">text_output</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">text_output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Now to run the model on your prompt
</span><span class="n">model_on_prompt</span><span class="p">(</span><span class="s">"What can I use LLMs for?"</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="ML" /><category term="Python" /><category term="Docker" /><summary type="html"><![CDATA[Getting started with LLMs locally]]></summary></entry><entry><title type="html">VPN over VPN on OpenWrt</title><link href="https://tales.fromprod.com/2022/347/VPN-over-VPN-on-Openwrt.html" rel="alternate" type="text/html" title="VPN over VPN on OpenWrt" /><published>2022-12-13T19:00:00+00:00</published><updated>2022-12-13T19:00:00+00:00</updated><id>https://tales.fromprod.com/2022/347/VPN-over-VPN-on-Openwrt</id><content type="html" xml:base="https://tales.fromprod.com/2022/347/VPN-over-VPN-on-Openwrt.html"><![CDATA[<h1 id="vpn-over-vpn-on-openwrt-on-one-device">VPN over VPN on Openwrt on one device</h1>

<p>OpenWrt has reasonable <a href="https://openwrt.org/docs/guide-user/services/vpn/wireguard/client">guides</a> on using your router as a WireGuard client but it’s missing a how to on running VPN over VPN. This article will close that gap</p>

<h2 id="why-run-vpn-over-vpn">Why run VPN over VPN?</h2>

<p>This guide exists because a certain UK ISP has terrible peering with another continent. A mitigation for this issue was to send traffic first to a UK VPN server with much better peering connections, and then send the actual VPN traffic to that other continent to appear there for the “first time”</p>

<h3 id="terminology">Terminology</h3>

<ul>
  <li>OuterVPN - innervpn.example.com - The VPN closest to you, that you’re using to take advantage of the better peering. The traffic exiting here is for the second VPN server.</li>
  <li>InnerVPN - outervpn.example.com - The VPN on another continent. The traffic existing here is the normal traffic you wanted to go over a VPN.</li>
</ul>

<h3 id="why-do-vpn-over-vpn-on-one-device">Why do VPN over VPN on one device?</h3>

<p>VPN over VPN is most commonly done by having one device do the connection to Outer VPN, and another (having the lan of the first device as its WAN) do the connection do the connection to InnerVPN. This is common because most routers are fairly slow and doing VPN over VPN slows the network performance too much. It’s also simpler to configure and debug.</p>

<p>However, there are now reasonably powerful devices like the Raspberry Pi 4 which can do this VPN over VPN (WireGuard) and achieve &gt; 200Mb/s. This means rather than needing so many devices you can do it all on one and only have to maintain one device.</p>

<h2 id="how-to-set-up-the-initial-wireguard-connection">How to set up the initial WireGuard connection?</h2>

<p>Follow this guide from <a href="https://www.azirevpn.com/support/guides/router/openwrt/wireguard">azirevpn</a> as it’s one of the better ones.</p>

<h2 id="now-i-have-my-inital-connection-how-to-do-i-do-vpn-over-vpn">Now I have my inital connection, how to do I do VPN over VPN?</h2>

<p>Assuming you have your Wireguard.conf file, you can follow that guide again but naming the new interface differently. Then, you should obtain the IP address of the InnerVPN server. These can be obtained via the following</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>dig outervpn.example.com

<span class="p">;</span> &lt;&lt;<span class="o">&gt;&gt;</span> DiG 9.18.1-1ubuntu1.2-Ubuntu &lt;&lt;<span class="o">&gt;&gt;</span> outervpn.example.com
<span class="p">;;</span> global options: +cmd
<span class="p">;;</span> Got answer:
<span class="p">;;</span> -&gt;&gt;HEADER<span class="o">&lt;&lt;-</span> <span class="no">opcode</span><span class="sh">: QUERY, status: NOERROR, id: 49846
;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 65494
;; QUESTION SECTION:
;vpn.example.com.	IN	A

;; ANSWER SECTION:
outervpn.example.com. 60 IN	A	192.0.2.240
outervpn.example.com. 60 IN	A	192.0.0.240

;; Query time: 32 msec
;; SERVER: 127.0.0.53#53(127.0.0.53) (UDP)
;; WHEN: Tue Dec 13 18:56:44 GMT 2022
;; MSG SIZE  rcvd: 89
</span></code></pre></div></div>

<p>Once you have the IP addresses, you should edit the <code class="language-plaintext highlighter-rouge">Allowed IPs</code> of the peer of OuterVPN to remove <code class="language-plaintext highlighter-rouge">0.0.0.0/0</code> and add the IPs obtained via the DNS lookup, each suffixed with <code class="language-plaintext highlighter-rouge">/32</code></p>

<p>Hit Save and Save and Apply, and you should be in business.</p>

<p>You can confirm this is working as expected by pinging the <code class="language-plaintext highlighter-rouge">innervpn.example.com</code> and seeing that this has a faster response than pinging <code class="language-plaintext highlighter-rouge">outervpn.example.com</code> and that both of these are faster than pinging a random server. If this isn’t true, something’s configured wrong.</p>

<h2 id="why-does-this-work">Why does this work?</h2>

<p>Routers send traffic to the most specific route in their routing table, and then fall back to their default route.</p>

<p>In the configuration above, we have a <code class="language-plaintext highlighter-rouge">/32</code> (exact IP address) route for the <code class="language-plaintext highlighter-rouge">outervpn.example.com</code> IPs, which is over the OuterVPN tunnel.</p>

<p>For your normal traffic, it will go over the <code class="language-plaintext highlighter-rouge">0.0.0.0/0</code> route which goes over the InnerVPN tunnel.</p>

<p>Your traffic to <code class="language-plaintext highlighter-rouge">innervpn.example.com</code> will go via the default route and out over your normal internet.</p>

<h2 id="gotchas">Gotchas</h2>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Route Allowed IPs</code> is actually in the <code class="language-plaintext highlighter-rouge">Peer Configuration</code> of the WireGuard interface settings on Luci rather than the interface itself. This must be set to true for the routes to be created properly</li>
  <li><code class="language-plaintext highlighter-rouge">MTU</code> being misconfigured on each interface is a common reason for slowdowns/random latency. Ensure that the MTU of your first tunnel is at most (line MTU - 80) and the second tunnel is at most (first tunnel MTU - 80). 80 obtained from <a href="https://projectcalico.docs.tigera.io/networking/mtu#determine-mtu-size">here</a>. This is particularly relevant as WireGuard sets the <code class="language-plaintext highlighter-rouge">Don't Fragment</code> bit on its packets, which can cause high packetloss.</li>
</ul>]]></content><author><name></name></author><category term="OpenWrt" /><category term="VPN" /><category term="WireGuard" /><summary type="html"><![CDATA[VPN over VPN on Openwrt on one device]]></summary></entry><entry><title type="html">Why LIST is a scary permission on Kubernetes</title><link href="https://tales.fromprod.com/2022/202/Why-Listing-Is-Scary_On-K8s.html" rel="alternate" type="text/html" title="Why LIST is a scary permission on Kubernetes" /><published>2022-07-21T20:00:00+01:00</published><updated>2022-07-21T20:00:00+01:00</updated><id>https://tales.fromprod.com/2022/202/Why-Listing-Is-Scary_On-K8s</id><content type="html" xml:base="https://tales.fromprod.com/2022/202/Why-Listing-Is-Scary_On-K8s.html"><![CDATA[<h1 id="why-list-is-a-scary-permission-on-kubernetes">Why LIST is a scary permission on Kubernetes</h1>

<p>The list response contains all items in full, not just their name. This means the <code class="language-plaintext highlighter-rouge">list</code> permission should never be given to a role that doesn’t already have the <code class="language-plaintext highlighter-rouge">get</code> permission.</p>

<h2 id="example-misuse">Example misuse</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c"># Create example A, which can only list secrets in the default namespace</span>
<span class="c"># It does not have the GET permission</span>
kubectl create serviceaccount only-list-secrets-sa
kubectl create role only-list-secrets-role <span class="nt">--verb</span><span class="o">=</span>list <span class="nt">--resource</span><span class="o">=</span>secrets
kubectl create rolebinding only-list-secrets-default-ns <span class="nt">--role</span><span class="o">=</span>only-list-secrets-role <span class="nt">--serviceaccount</span><span class="o">=</span>default:only-list-secrets-sa
<span class="c"># Now to impersonate that service account</span>
kubectl proxy &amp;
<span class="c"># Create a secret to get</span>
kubectl create secret generic abc
<span class="c"># Prove we cannot get that secret</span>
curl http://127.0.0.1:8001/api/v1/namespaces/default/secrets/abc <span class="nt">-H</span> <span class="s2">"Authorization: Bearer </span><span class="si">$(</span>kubectl <span class="nt">-n</span> default get secrets <span class="nt">-ojson</span> | jq <span class="s1">'.items[]| select(.metadata.annotations."kubernetes.io/service-account.name"=="only-list-secrets-sa")| .data.token'</span> | <span class="nb">tr</span> <span class="nt">-d</span> <span class="s1">'"'</span> | <span class="nb">base64</span> <span class="nt">-d</span><span class="si">)</span><span class="s2">"</span>
<span class="o">{</span>
  <span class="s2">"kind"</span>: <span class="s2">"Status"</span>,
  <span class="s2">"apiVersion"</span>: <span class="s2">"v1"</span>,
  <span class="s2">"metadata"</span>: <span class="o">{</span>
  <span class="o">}</span>,
  <span class="s2">"status"</span>: <span class="s2">"Failure"</span>,
  <span class="s2">"message"</span>: <span class="s2">"secrets </span><span class="se">\"</span><span class="s2">abc</span><span class="se">\"</span><span class="s2"> is forbidden: User </span><span class="se">\"</span><span class="s2">system:serviceaccount:default:only-list-secrets-sa</span><span class="se">\"</span><span class="s2"> cannot get resource </span><span class="se">\"</span><span class="s2">secrets</span><span class="se">\"</span><span class="s2"> in API group </span><span class="se">\"\"</span><span class="s2"> in the namespace </span><span class="se">\"</span><span class="s2">default</span><span class="se">\"</span><span class="s2">"</span>,
  <span class="s2">"reason"</span>: <span class="s2">"Forbidden"</span>,
  <span class="s2">"details"</span>: <span class="o">{</span>
    <span class="s2">"name"</span>: <span class="s2">"abc"</span>,
    <span class="s2">"kind"</span>: <span class="s2">"secrets"</span>
  <span class="o">}</span>,
  <span class="s2">"code"</span>: 403
<span class="o">}</span>
<span class="c"># Now to get all secrets in the default namespace, despite not having "get" permission</span>
curl http://127.0.0.1:8001/api/v1/namespaces/default/secrets?limit<span class="o">=</span>500 <span class="nt">-H</span> <span class="s2">"Authorization: Bearer </span><span class="si">$(</span>kubectl <span class="nt">-n</span> default get secrets <span class="nt">-ojson</span> | jq <span class="s1">'.items[]| select(.metadata.annotations."kubernetes.io/service-account.name"=="only-list-secrets-sa")| .data.token'</span> | <span class="nb">tr</span> <span class="nt">-d</span> <span class="s1">'"'</span> | <span class="nb">base64</span> <span class="nt">-d</span><span class="si">)</span><span class="s2">"</span>
<span class="o">{</span>
  <span class="s2">"kind"</span>: <span class="s2">"SecretList"</span>,
  <span class="s2">"apiVersion"</span>: <span class="s2">"v1"</span>,
  <span class="s2">"metadata"</span>: <span class="o">{</span>
    <span class="s2">"selfLink"</span>: <span class="s2">"/api/v1/namespaces/default/secrets"</span>,
    <span class="s2">"resourceVersion"</span>: <span class="s2">"17718246"</span>
  <span class="o">}</span>,
  <span class="s2">"items"</span>: <span class="o">[</span>
  REDACTED : REDACTED
  <span class="o">]</span>
<span class="o">}</span>
<span class="c"># Cleanup</span>
kubectl delete serviceaccount only-list-secrets-sa
kubectl delete role only-list-secrets-role <span class="nt">--verb</span><span class="o">=</span>list <span class="nt">--resource</span><span class="o">=</span>secrets
kubectl delete rolebinding only-list-secrets-default-ns <span class="nt">--role</span><span class="o">=</span>only-list-secrets-role <span class="nt">--serviceaccount</span><span class="o">=</span>default:only-list-secrets-sa
kubectl delete secret abc
<span class="c"># Kill backgrounded kubectl proxy</span>
<span class="nb">kill</span> <span class="s2">"%</span><span class="si">$(</span><span class="nb">jobs</span> | <span class="nb">grep</span> <span class="s2">"kubectl proxy"</span> | <span class="nb">cut</span> <span class="nt">-d</span> <span class="o">[</span> <span class="nt">-f</span> 2| <span class="nb">cut</span> <span class="nt">-d</span> <span class="o">]</span> <span class="nt">-f</span> 1<span class="si">)</span><span class="s2">"</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="Kubernetes" /><category term="APIs" /><summary type="html"><![CDATA[Why LIST is a scary permission on Kubernetes]]></summary></entry><entry><title type="html">Attempt 2 - Managing Google Groups via the API, aka what they don’t want you to do!</title><link href="https://tales.fromprod.com/2022/011/improved-managing-google-groups.html" rel="alternate" type="text/html" title="Attempt 2 - Managing Google Groups via the API, aka what they don’t want you to do!" /><published>2022-01-11T19:00:00+00:00</published><updated>2022-01-11T19:00:00+00:00</updated><id>https://tales.fromprod.com/2022/011/improved-managing-google-groups</id><content type="html" xml:base="https://tales.fromprod.com/2022/011/improved-managing-google-groups.html"><![CDATA[<h1 id="attempt-2---managing-google-groups-via-the-api-despite-their-best-efforts">Attempt 2 - Managing Google Groups via the API, despite their best efforts</h1>
<p>Due to some issues with the groupsService.List() (still pending with Google Support) I found a cleaner way to find the groups, by using a lookup based on the group email address.
I have rewritten this guide to use this instead, as it’s a more sensible way of approaching this problem. The old guide will remain as it should work…</p>

<h2 id="managing-google-groups-via-the-api-despite-their-best-efforts">Managing Google Groups via the API, despite their best efforts</h2>
<p>Google have made it difficult to do this, they somewhat document two different APIs to achieve this, with limited success. This is especially true if you want to use a service account rather than a user API token for the management.</p>

<ul>
  <li><a href="https://developers.google.com/admin-sdk/directory/v1/guides/manage-groups">Using the directory API</a></li>
  <li><a href="https://cloud.google.com/identity/docs/how-to/create-dynamic-groups">Using the Cloud Identity APIs - newer and seems to be preferred going forward</a></li>
</ul>

<p>At the time of writing, these are not sufficiently detailed to do more than work out those are the APIs to use. That’s where this guide comes in.</p>

<h2 id="what-this-will-help-you-achieve">What this will help you achieve</h2>

<p>A golang binary which manages the membership of a Google Group for you. The steps will likely apply to the other language client libraries</p>

<h2 id="prerequisites">Prerequisites</h2>
<ul>
  <li>Google Cloud Identity Premium</li>
  <li>A paid for Google Workspace</li>
  <li>A Google cloud Service Account (SA)
    <ul>
      <li>An API key for that SA</li>
      <li>The email address of that SA</li>
      <li>This SA requires <strong>no permissions at all</strong> in the cloud console</li>
    </ul>
  </li>
  <li>The google group you wish to manage
    <ul>
      <li>You should add the SA’s email address as an “OWNER” of that group, and change the subscription to “no emails” as it can’t receive them.</li>
    </ul>
  </li>
</ul>

<h3 id="dependencies">Dependencies</h3>
<ul>
  <li>A source of email addresses to add to your group</li>
  <li>The <a href="https://pkg.go.dev/google.golang.org/api@v0.51.0/cloudidentity/v1">cloud identity client library</a></li>
  <li>The <a href="https://pkg.go.dev/google.golang.org/api@v0.52.0/option">Google API options library</a></li>
</ul>

<p>The following is example code and won’t compile without changes, and lacks niceties like error handling and retrying in the face of inevitable errors.</p>

<p>This should provide a clearer understanding of the hierarchy of the Google Groups data model.</p>

<div class="language-golang highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="p">(</span>
	<span class="c">//Whatever other deps you need go here</span>

	<span class="n">cloudidentity</span> <span class="s">"google.golang.org/api/cloudidentity/v1"</span>
	<span class="n">goption</span> <span class="s">"google.golang.org/api/option"</span>
<span class="p">)</span>

<span class="c">// Variables to replace in this sample (nonworking) code</span>
<span class="c">// requiredGroup@example.com -&gt; The email address of the google group you care about</span>
<span class="c">// "a@a.com", "b@a.com" -&gt; The actual list of emails you want added</span>
<span class="c">// addDelta -&gt; A function to say which emails need added to the group based on current emails</span>
<span class="c">// removeDelta -&gt; A function to say which emails need removed from the group based on current emails</span>

<span class="k">func</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>

	<span class="c">// Create your goptions from your credential file.</span>
	<span class="c">// This is the Service Account Key you downloaded during</span>
	<span class="c">// The prerequisites.</span>
	<span class="n">goptions</span> <span class="o">:=</span> <span class="n">goption</span><span class="o">.</span><span class="n">WithCredentialsFile</span><span class="p">(</span><span class="s">"/some/file/location.json"</span><span class="p">)</span>

	<span class="n">ctx</span> <span class="o">:=</span> <span class="n">context</span><span class="o">.</span><span class="n">Background</span><span class="p">()</span>
	<span class="n">cis</span> <span class="o">:=</span> <span class="n">cloudidentity</span><span class="o">.</span><span class="n">NewService</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">goptions</span><span class="p">)</span>

	<span class="c">// Next you'll want to get the group you're interested in</span>
	<span class="c">// The only way I found was to get all accessible groups</span>
	<span class="c">// Then filter for the relevant email address</span>

	<span class="n">groupsService</span> <span class="o">:=</span> <span class="n">cloudidentity</span><span class="o">.</span><span class="n">NewGroupsService</span><span class="p">(</span><span class="n">cis</span><span class="p">)</span>

	<span class="c">// Different from old verison</span>
	<span class="c">// Finding the groupName by using the fact that the GroupKeyId </span>
	<span class="c">// Is actually the email address of the group</span>
	<span class="c">// The group name is a magic thing of format  groups/{group_id}</span>
	<span class="n">groupsServiceLookup</span> <span class="o">:=</span> <span class="n">groupsService</span><span class="o">.</span><span class="n">Lookup</span><span class="p">()</span>
	<span class="n">groupsServiceLookup</span><span class="o">.</span><span class="n">GroupKeyId</span><span class="p">(</span><span class="n">ggroupemail</span><span class="p">)</span>

	<span class="n">groupLookupResponse</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">groupsServiceLookup</span><span class="o">.</span><span class="n">Do</span><span class="p">()</span>
	<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
		<span class="n">log</span><span class="o">.</span><span class="n">Fatal</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
	<span class="p">}</span>

	<span class="c">// If we wanted the group directly</span>
	<span class="c">// reqGroup, err := gs.Get(groupLookupResponse.Name).Do()</span>

	<span class="c">// Now to get the membership of the group, so we can see the emails of the current members</span>

	<span class="n">gms</span> <span class="o">:=</span> <span class="n">cloudidentity</span><span class="o">.</span><span class="n">NewGroupsMembershipsService</span><span class="p">(</span><span class="n">cis</span><span class="p">)</span>

	<span class="c">// Response containing list of memberships</span>
	<span class="n">lmr</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">gms</span><span class="o">.</span><span class="n">List</span><span class="p">(</span><span class="n">groupLookupResponse</span><span class="o">.</span><span class="n">Name</span><span class="p">)</span><span class="o">.</span><span class="n">Do</span><span class="p">()</span>
	<span class="c">// Pulling out just the memberships</span>
	<span class="n">currentMemberships</span> <span class="o">:=</span> <span class="n">lmr</span><span class="o">.</span><span class="n">Memberships</span>

	<span class="k">var</span> <span class="n">currentEmails</span> <span class="p">[]</span><span class="kt">string</span>

	<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">member</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">currentMemberships</span> <span class="p">{</span>
		<span class="c">// The EntityKey == PreferredMemberKey == the user email</span>
		<span class="n">email</span> <span class="o">:=</span> <span class="n">member</span><span class="o">.</span><span class="n">PreferredMemberKey</span><span class="o">.</span><span class="n">Id</span>
		<span class="n">currentEmails</span> <span class="o">=</span> <span class="nb">append</span><span class="p">(</span><span class="n">currentEmails</span><span class="p">,</span> <span class="n">email</span><span class="p">)</span>
	<span class="p">}</span>

	<span class="n">desiredEmails</span> <span class="o">:=</span> <span class="p">[]</span><span class="kt">string</span><span class="p">{</span><span class="s">"a@a.com"</span><span class="p">,</span> <span class="s">"b@a.com"</span><span class="p">}</span>

	<span class="c">//The following functions aren't defined, you need to define this logic yourself</span>

	<span class="c">// Example if you wish to only add the new emails</span>
	<span class="c">// Rather than deal with 409 which you get</span>
	<span class="c">// if the email is already a member</span>
	<span class="n">additionalEmails</span> <span class="o">:=</span> <span class="n">addDelta</span><span class="p">(</span><span class="n">desiredEmails</span><span class="p">,</span> <span class="n">currentEmails</span><span class="p">)</span>
	<span class="c">// Example if you wish to remove any members who shouldn't be there</span>
	<span class="n">emailsToRemove</span> <span class="o">:=</span> <span class="n">removeDelta</span><span class="p">(</span><span class="n">desiredEmails</span><span class="p">,</span> <span class="n">currentEmails</span><span class="p">)</span>

	<span class="c">// Now to add the new members</span>

	<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">email</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">additionalEmails</span> <span class="p">{</span>
		<span class="n">key</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="n">cloudidentity</span><span class="o">.</span><span class="n">EntityKey</span><span class="p">{</span><span class="n">Id</span><span class="o">:</span> <span class="n">email</span><span class="p">}</span>
		<span class="n">roles</span> <span class="o">:=</span> <span class="p">[]</span><span class="o">*</span><span class="n">cloudidentity</span><span class="o">.</span><span class="n">MembershipRole</span><span class="p">{</span><span class="o">&amp;</span><span class="n">cloudidentity</span><span class="o">.</span><span class="n">MembershipRole</span><span class="p">{</span><span class="n">Name</span><span class="o">:</span> <span class="s">"MEMBER"</span><span class="p">}}</span>
		<span class="c">// Despite the docs saying it's Member by default, we must explicitly set it</span>
		<span class="c">// Or you will get ERROR: googleapi: Error 400: resource.roles must be specified, badRequest</span>
		<span class="c">// when trying to create the membership</span>

		<span class="n">mem</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="n">cloudidentity</span><span class="o">.</span><span class="n">Membership</span><span class="p">{</span><span class="n">PreferredMemberKey</span><span class="o">:</span> <span class="n">key</span><span class="p">,</span> <span class="n">Roles</span><span class="o">:</span> <span class="n">roles</span><span class="p">}</span>

		<span class="c">// This part youll want to make retriable</span>
		<span class="c">// Any 409's are "fine" as it means the member already exists</span>
		<span class="c">// Using the "Name" found earlier as it's annoying to create due to format</span>
		<span class="n">_</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">gms</span><span class="o">.</span><span class="n">Create</span><span class="p">(</span><span class="n">relevantGroup</span><span class="o">.</span><span class="n">Name</span><span class="p">,</span> <span class="n">mem</span><span class="p">)</span><span class="o">.</span><span class="n">Do</span><span class="p">()</span>
		<span class="n">errStr</span> <span class="o">:=</span> <span class="n">fmt</span><span class="o">.</span><span class="n">Sprint</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
		<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">strings</span><span class="o">.</span><span class="n">Contains</span><span class="p">(</span><span class="n">errStr</span><span class="p">,</span> <span class="s">"Error 409"</span><span class="p">)</span> <span class="p">{</span>
			<span class="n">log</span><span class="o">.</span><span class="n">Error</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
			<span class="k">continue</span>
		<span class="p">}</span>

	<span class="p">}</span>

	<span class="c">// Now to remove the extra members</span>

	<span class="c">// Have a horrible loop as there doesn't seem to be a nice way to get a membership ID...</span>
	<span class="c">// MembershipLookupCall doesn't exist :(</span>

	<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">email</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">emailsForRemoval</span> <span class="p">{</span>

		<span class="n">found</span> <span class="o">:=</span> <span class="no">false</span>

		<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">Membership</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">currentMemberships</span> <span class="p">{</span>
			<span class="k">if</span> <span class="n">Membership</span><span class="o">.</span><span class="n">PreferredMemberKey</span><span class="o">.</span><span class="n">Id</span> <span class="o">==</span> <span class="n">email</span> <span class="p">{</span>
				<span class="n">found</span> <span class="o">=</span> <span class="no">true</span>
				<span class="n">_</span><span class="p">,</span> <span class="n">err</span> <span class="o">:=</span> <span class="n">gms</span><span class="o">.</span><span class="n">Delete</span><span class="p">(</span><span class="n">Membership</span><span class="o">.</span><span class="n">Name</span><span class="p">)</span><span class="o">.</span><span class="n">Do</span><span class="p">()</span>
				<span class="k">if</span> <span class="n">err</span> <span class="o">!=</span> <span class="no">nil</span> <span class="p">{</span>
					<span class="n">e</span> <span class="o">:=</span> <span class="n">fmt</span><span class="o">.</span><span class="n">Errorf</span><span class="p">(</span><span class="s">"Encountered error while deleting membership %+v"</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
					<span class="n">log</span><span class="o">.</span><span class="n">Error</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
					<span class="k">continue</span>
				<span class="p">}</span>
			<span class="p">}</span>
		<span class="p">}</span>
		<span class="k">if</span> <span class="o">!</span><span class="n">found</span> <span class="p">{</span>
			<span class="n">log</span><span class="o">.</span><span class="n">Error</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
			<span class="k">continue</span>
		<span class="p">}</span>

	<span class="p">}</span>

<span class="p">}</span>

</code></pre></div></div>]]></content><author><name></name></author><category term="Google" /><category term="APIs" /><category term="Golang" /><category term="Go" /><summary type="html"><![CDATA[Attempt 2 - Managing Google Groups via the API, despite their best efforts Due to some issues with the groupsService.List() (still pending with Google Support) I found a cleaner way to find the groups, by using a lookup based on the group email address. I have rewritten this guide to use this instead, as it’s a more sensible way of approaching this problem. The old guide will remain as it should work…]]></summary></entry><entry><title type="html">Running a Kubernetes native x86_64 application on Raspberry Pis, and why you shouldn’t!</title><link href="https://tales.fromprod.com/2021/342/x86-on-k8s-on-raspberry-pi.html" rel="alternate" type="text/html" title="Running a Kubernetes native x86_64 application on Raspberry Pis, and why you shouldn’t!" /><published>2021-12-08T19:00:00+00:00</published><updated>2021-12-08T19:00:00+00:00</updated><id>https://tales.fromprod.com/2021/342/x86-on-k8s-on-raspberry-pi</id><content type="html" xml:base="https://tales.fromprod.com/2021/342/x86-on-k8s-on-raspberry-pi.html"><![CDATA[<h1 id="running-a-kubernetes-native-x86_64-application-on-raspberry-pis-and-why-you-shouldnt">Running a Kubernetes native x86_64 application on Raspberry Pis, and why you shouldn’t!</h1>

<p>While this guide does work, don’t do this. Emulation is <em>slow</em> and Raspberry Pi CPUs (even overclocked to 2GHz) are slower!</p>

<p>Also, you have to use x86_64 emulation (rather than KVM) because Pis use an ARM instruction set rather than x86.</p>

<h2 id="cpu-benchmark-for-slowness">CPU benchmark for slowness</h2>
<p>This benchmark is terrible, but gives an indication of single threaded performance</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#On my work machine</span>
<span class="nb">time dd </span><span class="k">if</span><span class="o">=</span>/dev/urandom <span class="nv">of</span><span class="o">=</span>/dev/null <span class="nv">bs</span><span class="o">=</span>2000000 <span class="nv">count</span><span class="o">=</span>100

real	0m4.264s
user	0m0.000s
sys	0m4.264s

<span class="c"># On a VM on k3s-005</span>
<span class="nv">$ </span><span class="nb">time dd </span><span class="k">if</span><span class="o">=</span>/dev/urandom <span class="nv">of</span><span class="o">=</span>/dev/null <span class="nv">bs</span><span class="o">=</span>2000000 <span class="nv">count</span><span class="o">=</span>100

real 0m 19.08s
user 0m 0.03s
sys 0m 18.94s

<span class="c"># Natively on that Pi</span>
pi@node-005:~ <span class="nv">$ </span><span class="nb">time dd </span><span class="k">if</span><span class="o">=</span>/dev/urandom <span class="nv">of</span><span class="o">=</span>/dev/null <span class="nv">bs</span><span class="o">=</span>2000000 <span class="nv">count</span><span class="o">=</span>100

real	0m2.784s
user	0m0.004s
sys	0m2.769s
</code></pre></div></div>

<h2 id="architecture">Architecture</h2>

<div align="center">x86_64 Application</div>

<div align="center">Kubernetes (k3s)</div>

<div align="center">QEMU x86_64 emulation</div>

<div align="center">Raspberry Pis</div>

<h2 id="equipment-in-use">Equipment in use</h2>
<ul>
  <li>4 * Pi 4 8GB</li>
  <li>SSD enclosure per Pi supporting UASP</li>
  <li>SSD per Pi</li>
  <li>Ethernet switch</li>
  <li>A router</li>
  <li>Power</li>
  <li>misc cables</li>
</ul>

<h2 id="oss-in-use">OSs in use</h2>
<ul>
  <li>Raspbian 64 bit on the Pis</li>
  <li>Alpine in the x86_64 VMs</li>
</ul>

<h2 id="setting-up-the-pis">Setting up the Pis</h2>
<p>We installed 64 bit Raspbian on the SSDs and booted from them.</p>

<h3 id="installing-the-dependencies">Installing the dependencies</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt upgrade <span class="nt">-y</span> <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt <span class="nb">install</span> <span class="nt">-y</span> qemu nmon virtinst qemu-utils qemu-system-x86 tmux vim dnsmasq-utils dnsmasq-base iptables libvirt-daemon-system
</code></pre></div></div>

<h3 id="overclocking-the-pis">Overclocking the Pis</h3>
<p>The Raspberry Pi doesn’t have the fastest CPU, so we overclocked it to 2GHz and over_voltage 6 to keep the warranty. Full guide <a href="https://www.seeedstudio.com/blog/2020/02/12/how-to-safely-overclock-your-raspberry-pi-4-to-2-147ghz/">https://www.seeedstudio.com/blog/2020/02/12/how-to-safely-overclock-your-raspberry-pi-4-to-2-147ghz/</a></p>

<h3 id="setting-up-the-qemu-groups">Setting up the QEMU groups</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>groupadd libvirt-qemu
groupadd libvirt
groupadd libvirtd
useradd <span class="nt">-g</span> libvirt-qemu libvirt-qemu
</code></pre></div></div>

<h3 id="setting-up-swap-in-case-its-need-since-8gb-ram-isnt-much">Setting up swap (in case it’s need since 8GB RAM isn’t much)</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Create and mount swap</span>
<span class="nb">sudo </span>fallocate <span class="nt">-l</span> 64G /swapfile <span class="o">&amp;&amp;</span> <span class="nb">sudo chmod </span>600 /swapfile <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>mkswap /swapfile <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>swapon /swapfile
</code></pre></div></div>
<p>Next add an entry to fstab so that the swap is mounted on boot.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>su <span class="nt">-c</span> <span class="s2">"echo '/swapfile swap swap defaults 0 0' &gt;&gt; /etc/fstab"</span>
</code></pre></div></div>
<p>Next check that trim works on the PI, if it’s working you should get something similar to the following</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>fstrim <span class="nt">-av</span>
/boot: 0 B <span class="o">(</span>0 bytes<span class="o">)</span> trimmed
/: 19.9 GiB <span class="o">(</span>21294051328 bytes<span class="o">)</span> trimmed
</code></pre></div></div>
<p>If this fails, you’ll need to follow <a href="https://www.jeffgeerling.com/blog/2020/enabling-trim-on-external-ssd-on-raspberry-pi">https://www.jeffgeerling.com/blog/2020/enabling-trim-on-external-ssd-on-raspberry-pi</a></p>

<p>Due to the high volume of writes expected since the SSD will be used as RAM, configure TRIM to run frequently to prevent rapid deterioration of the SSD.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># trimming every 2 min:</span>
<span class="nb">sudo </span>vi /lib/systemd/system/fstrim.timer
<span class="c"># change:</span>
<span class="o">[</span>Timer]
<span class="nv">OnCalender</span><span class="o">=</span><span class="k">*</span>:0/2
<span class="nv">AccuracySec</span><span class="o">=</span>0

<span class="nb">sudo </span>systemctl daemon-reload
</code></pre></div></div>

<h3 id="setting-up-the-bridge-networking-so-the-vms-can-connect-directly-helpful-for-k8s">Setting up the Bridge networking so the VMs can connect directly (helpful for k8s)</h3>
<p>Largely following <a href="https://www.raspberrypi.com/documentation/computers/configuration.html#bridging">https://www.raspberrypi.com/documentation/computers/configuration.html#bridging</a></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>su <span class="nt">-c</span> <span class="s2">"echo '[NetDev]
Name=br0
Kind=bridge
' &gt;&gt; /etc/systemd/network/bridge-br0.netdev"</span>

<span class="nb">sudo </span>su <span class="nt">-c</span> <span class="s2">"echo '[Match]
Name=eth0

[Network]
Bridge=br0
' &gt;&gt; /etc/systemd/network/bridge-br0.netdev"</span>
<span class="nb">sudo </span>systemctl <span class="nb">enable </span>systemd-networkd

</code></pre></div></div>
<p>Next ensure that eth0 is on the bridge network, and it’s the bridge that does dhcp rather than other interfaces</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>vim /etc/dhcpcd.conf
<span class="c"># At top add the following, without the #</span>
<span class="c"># denyinterfaces wlan0 eth0</span>

<span class="c"># at the very bottom add, without the #</span>
<span class="c"># interface br0</span>

</code></pre></div></div>
<p>Next is to let QEMU use this bridge, largely following <a href="https://wiki.archlinux.org/title/QEMU#Bridged_networking_using_qemu-bridge-helper">https://wiki.archlinux.org/title/QEMU#Bridged_networking_using_qemu-bridge-helper</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo mkdir</span> /etc/qemu

<span class="c"># Add all that into a script (run as root):</span>
<span class="c">#!bin/bash</span>

<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; /etc/systemd/network/bridge-br0.netdev
[NetDev]
Name=br0
Kind=bridge
</span><span class="no">EOT

</span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; /etc/systemd/network/br0-member-eth0.network
[Match]
Name=eth0

[Network]
Bridge=br0
</span><span class="no">EOT

</span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'1s/^/denyinterfaces wlan0 eth0 \n/'</span> /etc/dhcpcd.conf
<span class="nb">echo</span> <span class="s2">"interface br0"</span> <span class="o">&gt;&gt;</span> /etc/dhcpcd.conf

<span class="k">if</span> <span class="o">[[</span> <span class="o">!</span> <span class="nt">-d</span> <span class="s2">"/etc/qemu"</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then
  </span><span class="nb">mkdir</span> /etc/qemu
<span class="k">fi
</span><span class="nb">echo</span> <span class="s2">"allow br0"</span> <span class="o">&gt;</span> /etc/qemu/bridge.conf


<span class="c">#then need to execute later</span>
systemctl <span class="nb">enable </span>system-networkd

</code></pre></div></div>

<h3 id="running-the-x86-vm">Running the x86 VM</h3>
<p>For the VM we used Alpine as it’s a light OS and compatible with k3s. You can choose your download from <a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://dl-cdn.alpinelinux.org/alpine/v3.15/releases/x86_64/alpine-virt-3.15.0-x86_64.iso
</code></pre></div></div>
<p>Next you’ll have to create a disk image for the Alpine VM, we created a 128GB sparse image given the size of the SSDs we used.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qemu-img create <span class="nt">-f</span> qcow2 alpine.qcow2 128G

</code></pre></div></div>

<p>Now to run the VM, this command must be run from a display because it attempts to open a window. It is possible to do this in a headless fashion, but we couldn’t get that working.
Each VM needs a unique mac address for the networking to work correctly</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>qemu-system-x86_64 <span class="nt">--name</span> alpine-node <span class="nt">-drive</span> <span class="nv">file</span><span class="o">=</span>/home/pi/alpine.qcow2 <span class="nt">-smp</span> <span class="nv">cpus</span><span class="o">=</span>4 <span class="nt">-m</span> 60G,slots<span class="o">=</span>4,maxmem<span class="o">=</span>61G <span class="nt">-accel</span> tcg,thread<span class="o">=</span>multi <span class="nt">-nic</span> bridge,br<span class="o">=</span>br0,model<span class="o">=</span>virtio-net-pci,mac<span class="o">=</span>52:54:00:12:34:50
</code></pre></div></div>
<p>Exciting options, 
<code class="language-plaintext highlighter-rouge">-accel tcg,thread=multi</code> enables the VM to use multiple host cores
<code class="language-plaintext highlighter-rouge">virtio-net-pci</code> allows a virtual nic that works with the bridge configured.</p>

<p>You should ensure each of these VMs have a unique hostname, and a static IP in your router. This will make k3s configuration much easier</p>

<h2 id="configuring-k3s">Configuring k3s</h2>
<p>For our setup, one Pi ran the k3s control plane natively (and didn’t have a VM running) and the other Pis each had a VM running. Those VMs were joined to the k3s cluster as worker nodes.</p>

<p>Before installing on the control node, follow <a href="https://rancher.com/docs/k3s/latest/en/advanced/#enabling-legacy-iptables-on-raspbian-buster">https://rancher.com/docs/k3s/latest/en/advanced/#enabling-legacy-iptables-on-raspbian-buster</a> to set up iptables correctly and <a href="https://rancher.com/docs/k3s/latest/en/advanced/#enabling-cgroups-for-raspbian-buster">https://rancher.com/docs/k3s/latest/en/advanced/#enabling-cgroups-for-raspbian-buster</a> to set up cgroups correctly.</p>

<p>Before installing on the (virtual) worker nodes, follow <a href="https://rancher.com/docs/k3s/latest/en/advanced/#additional-preparation-for-alpine-linux-setup">https://rancher.com/docs/k3s/latest/en/advanced/#additional-preparation-for-alpine-linux-setup</a></p>

<h3 id="installing-the-control-plane">Installing the control-plane</h3>
<p>Unfortunately, the easiest way to install k3s with systemd is running random scripts from the internet…</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo</span> <span class="nt">-i</span>
apt <span class="nb">install</span> <span class="nt">-y</span> curl
curl <span class="nt">-sfL</span> https://get.k3s.io | sh -
</code></pre></div></div>

<h2 id="prevent-pods-running-on-control-plane">Prevent pods running on control plane</h2>
<p>It’s generally a bad idea to run workloads on your control plane, especially in this case as our workloads with be x86 but the control plane is ARM64.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl taint nodes node-0001 node-role.kubernetes.io/master<span class="o">=</span><span class="nb">true</span>:NoSchedule
</code></pre></div></div>

<h3 id="adding-worker-nodes">Adding worker nodes</h3>
<p>Pretty simple, <a href="https://rancher.com/docs/k3s/latest/en/quick-start/#install-script">full guide here.</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apk add curl <span class="o">&amp;&amp;</span> curl <span class="nt">-sfL</span> https://get.k3s.io | <span class="nv">K3S_URL</span><span class="o">=</span>https://node-001:6443 <span class="nv">K3S_TOKEN</span><span class="o">=</span>SomeTokenFromControlPlane sh -
</code></pre></div></div>

<p>With this, the x86_64 workers nodes should be added the cluster. Each node should have a unique hostname and be connectable on that hostname from all nodes.</p>

<h2 id="success">Success?</h2>
<p>If you’re successful, you should have a working k3s cluster with workloads running on x86 (slowly!)</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pi@node-001:~ <span class="nv">$ </span>kubectl get nodes
NAME                            STATUS   ROLES                  AGE    VERSION
node-001                        Ready    control-plane,master   105m   v1.21.5+k3s2
k3s-002                         Ready    control-plane,master   100m   v1.21.5+k3s2
k3s-003                         Ready    control-plane,master   90m   v1.21.5+k3s2
k3s-004                         Ready    control-plane,master   80m   v1.21.5+k3s2
k3s-005                         Ready    control-plane,master   70m   v1.21.5+k3s2
</code></pre></div></div>
<h2 id="why-you-shouldnt-do-this">Why you shouldn’t do this</h2>
<p>Over 1.5 cores of the Pi is used by <em>k3s</em>, never mind the workloads we want to run!</p>

<p>Here’s a simple <a href="https://github.com/reactive-tech/kubegres">pod</a> which didn’t manage to start, even after 5 mins due to the CPU limitations.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pi@node-001:~ <span class="nv">$ </span>kubectl get pod <span class="nt">-w</span>
NAME                                              READY   STATUS              RESTARTS   AGE
kubegres-controller-manager-75b6765589-kvr97      1/2     ContainerCreating   0          4m54s
</code></pre></div></div>

<h2 id="conclusions">Conclusions</h2>
<p>Don’t run x86 on Pis, especially not on kubernetes! They just aren’t fast enough (yet)</p>]]></content><author><name></name></author><category term="Kubernetes" /><category term="QEMU" /><summary type="html"><![CDATA[Running a Kubernetes native x86_64 application on Raspberry Pis, and why you shouldn’t!]]></summary></entry></feed>